{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP: A Quick PyTorch 2.0 Tutorial\n",
    "\n",
    "In short:\n",
    "\n",
    "If you have a new GPU (NVIDIA 40XX or A100, A10G etc), you can \"compile\" your models and often see speed ups.\n",
    "\n",
    "**Before PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "### Train model ###\n",
    "\n",
    "### Test model ###\n",
    "```\n",
    "\n",
    "**After PyTorch 2.0:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model = create_model()\n",
    "compiled_model = torch.compile(model) # <- new!\n",
    "\n",
    "### Train model ### <- faster!\n",
    "\n",
    "### Test model ### <- faster!\n",
    "```\n",
    "\n",
    "Things to note:\n",
    "* TK - add where it doesn't work\n",
    "\n",
    "## TK - Resources to learn more\n",
    "* PyTorch 2.0 launch blog post - https://pytorch.org/get-started/pytorch-2.0/ \n",
    "* PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/ \n",
    "    * GitHub release notes - https://github.com/pytorch/pytorch/releases/tag/v2.0.0 (lots of info here!)\n",
    "* PyTorch default device context manager - https://github.com/pytorch/tutorials/pull/2220/files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current PyTorch version: 2.0.0+cu118 (should be 2.x+)\n",
      "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 if necessary\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\")\n",
    "    import torch\n",
    "    pt_version = torch.__version__\n",
    "    print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - New feature: globally set devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# See here: https://github.com/pytorch/tutorials/pull/2220/files \n",
    "import torch\n",
    "with torch.device('cuda'):\n",
    "    mod = torch.nn.Linear(20, 30)\n",
    "    print(mod.weight.device)\n",
    "    print(mod(torch.randn(128, 20)).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* add in info about PyTorch 2.0\n",
    "* a quick upgrade for speed ups\n",
    "* a quick note on which GPU will be needed (works best on NVIDIA GPUs, not macOS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Check GPU\n",
    "\n",
    "* **Note:** If you're running on Google Colab, you'll need to setup a GPU: runtime -> change runtime type -> hardware accelerator\n",
    "* Best speedups are on newer NVIDIA/AMD GPUs (this is because PyTorch 2.0 leverages new GPU hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU information:\n",
      "Thu Mar 16 16:19:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   45C    P2    35W / 320W |    371MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1001      G   /usr/lib/xorg/Xorg                 86MiB |\n",
      "|    0   N/A  N/A      1223      G   /usr/bin/gnome-shell               10MiB |\n",
      "|    0   N/A  N/A     73068      C   ...ch/env-nightly/bin/python      270MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU name: NVIDIA_GeForce_RTX_4080\n",
      "GPU capability score: (8, 9)\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "  else:\n",
    "    print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  # Replace spaces with \"_\" (for naming files later on)\n",
    "  gpu_name = gpu_name.replace(\" \", \"_\")\n",
    "  print(f'GPU name: {gpu_name}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  gpu_score = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {gpu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TK - add a table for NVIDIA GPUs and architectures etc and which lead to speedups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Simple training example \n",
    "\n",
    "* CIFAR10\n",
    "* ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchVision version: 0.15.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25557032\n"
     ]
    }
   ],
   "source": [
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "transforms = model_weights.transforms()\n",
    "model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU with score: (8, 9), enabling TensorFloat32 (TF32) computing (faster on new GPUs)\n"
     ]
    }
   ],
   "source": [
    "# TODO: speedups on larger GPUs will likely be seen with larger amounts of data\n",
    "# TK - also see here for using `torch.backends.cuda.matmul.allow_tf32` to enable TF32 on A100s/newer GPUS - https://github.com/pytorch/pytorch/blob/master/torch/_inductor/compile_fx.py#L86 \n",
    "\n",
    "if gpu_score >= (8, 0):\n",
    "  print(f\"[INFO] Using GPU with score: {gpu_score}, enabling TensorFloat32 (TF32) computing (faster on new GPUs)\")\n",
    "  # Set TF32 = True\n",
    "  IMAGE_SIZE = 224\n",
    "  torch.backends.cuda.matmul.allow_tf32 = True\n",
    "  transforms.crop_size = IMAGE_SIZE\n",
    "  transforms.resize_size = IMAGE_SIZE\n",
    "else:\n",
    "  transforms.crop_size = 224\n",
    "  transforms.resize_size = 224 # Resize to 32x32, CIFAR10 is 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=224\n",
       "    resize_size=224\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] Test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transforms)\n",
    "\n",
    "# Get the lengths of the datasets\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] Test dataset length: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "* Generally GPUs aren't the bottleneck of ML code\n",
    "* Data loading is the main bottleneck\n",
    "    * E.g. you want to get your data to the GPU as fast as possible = more workers (though in my experience this generally caps at about ~4 workers per GPU, though don't trust me, better to do your own experiments)\n",
    "* You want your GPUs to go brrrrr - https://horace.io/brrr_intro.html \n",
    "    * More here on crazy matmul improvements - https://twitter.com/cHHillee/status/1630274804795445248?s=20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 391 batches of size 128\n",
      "Test dataloader length: 79 batches of size 128\n",
      "Using number of workers: 16 (generally more workers means faster dataloading from CPU to GPU)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "import os\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details\n",
    "print(f\"Train dataloader length: {len(train_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"Using number of workers: {NUM_WORKERS} (generally more workers means faster dataloading from CPU to GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename to save the results\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_name = \"ResNet50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "def create_model():\n",
    "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "  # TK - adjust the output layer shape for CIFAR10\n",
    "  model.fc = torch.nn.Linear(2048, 10)\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28e8225c6c3449a8eb1d9bb4fabb478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e34c9d1a07844498d369afe485d8c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cbc14d3dfa4e49ab11ad2cb4af3824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.7721 | train_acc: 0.7322 | test_loss: 0.6501 | test_acc: 0.7804 | train_epoch_time: 110.3998 | test_epoch_time: 9.1594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b8214f00b48fc86b12e56537e65b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9656fdff94b452398fb7ddf66a30b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4383 | train_acc: 0.8483 | test_loss: 0.4706 | test_acc: 0.8444 | train_epoch_time: 109.8912 | test_epoch_time: 9.1496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e590b8f57fc4433080f1da1208b96db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5206069cf9e4444beb7afb35041e0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.3049 | train_acc: 0.8947 | test_loss: 0.4456 | test_acc: 0.8423 | train_epoch_time: 109.8841 | test_epoch_time: 9.2271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bb1a60291e426d86287a45f9f66a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ae5288bcc94b618f9f01c71ec6313f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.2309 | train_acc: 0.9204 | test_loss: 0.4313 | test_acc: 0.8591 | train_epoch_time: 109.9004 | test_epoch_time: 9.1894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62a5814115e4e638276ee033c4840b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0a27f870ed4afba9af5a872c62ab55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1701 | train_acc: 0.9411 | test_loss: 0.3599 | test_acc: 0.8832 | train_epoch_time: 109.8170 | test_epoch_time: 9.2094\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.08393430709838867 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3716688c9f4bceab895bbebee77750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606d6dd9b604464a9afcbb4df217a09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca9a8678f8145cf91bbdd4cc08df90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 0:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.8047 | train_acc: 0.7209 | test_loss: 0.6493 | test_acc: 0.7758 | train_epoch_time: 123.4870 | test_epoch_time: 17.0246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e4a85aeb7a4285bbffc126f230f135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b2e44fa74a4585a816165e21e0157f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.4395 | train_acc: 0.8502 | test_loss: 0.5214 | test_acc: 0.8228 | train_epoch_time: 98.0134 | test_epoch_time: 7.5135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeab8321f98e4ea8ad3c88dc562aabef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b272839465f44aa1939571c8af75ca2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.3184 | train_acc: 0.8894 | test_loss: 0.4231 | test_acc: 0.8561 | train_epoch_time: 98.0356 | test_epoch_time: 7.6120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5576f790b6b94277a72084a78341d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb9aca040b34580a97a48c4ce10db50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.2440 | train_acc: 0.9148 | test_loss: 0.3896 | test_acc: 0.8698 | train_epoch_time: 98.0249 | test_epoch_time: 7.4867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b75691bd9114832860d1b7d3366c64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d05cd5db53040ebbbb1b06b371e5235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.1794 | train_acc: 0.9378 | test_loss: 0.4060 | test_acc: 0.8698 | train_epoch_time: 98.0487 | test_epoch_time: 7.5143\n"
     ]
    }
   ],
   "source": [
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=0.003)\n",
    "\n",
    "compile_start_time = time.time()\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "compile_results = train(model=compiled_model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before tf32 (with compile)\n",
    "# Epoch: 2 | train_loss: 0.4303 | train_acc: 0.8524 | test_loss: 0.5928 | test_acc: 0.7969 | train_epoch_time: 98.1773 | test_epoch_time: 7.5189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graphs of results and compiled_results\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "compile_results_df = pd.DataFrame(compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772122</td>\n",
       "      <td>0.732217</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>110.399775</td>\n",
       "      <td>9.159359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438305</td>\n",
       "      <td>0.848274</td>\n",
       "      <td>0.470592</td>\n",
       "      <td>0.844442</td>\n",
       "      <td>109.891169</td>\n",
       "      <td>9.149639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304912</td>\n",
       "      <td>0.894689</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>0.842267</td>\n",
       "      <td>109.884116</td>\n",
       "      <td>9.227098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230868</td>\n",
       "      <td>0.920440</td>\n",
       "      <td>0.431279</td>\n",
       "      <td>0.859078</td>\n",
       "      <td>109.900380</td>\n",
       "      <td>9.189433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170133</td>\n",
       "      <td>0.941148</td>\n",
       "      <td>0.359897</td>\n",
       "      <td>0.883208</td>\n",
       "      <td>109.816973</td>\n",
       "      <td>9.209387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.772122   0.732217   0.650112  0.780360        110.399775   \n",
       "1    0.438305   0.848274   0.470592  0.844442        109.891169   \n",
       "2    0.304912   0.894689   0.445594  0.842267        109.884116   \n",
       "3    0.230868   0.920440   0.431279  0.859078        109.900380   \n",
       "4    0.170133   0.941148   0.359897  0.883208        109.816973   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         9.159359  \n",
       "1         9.149639  \n",
       "2         9.227098  \n",
       "3         9.189433  \n",
       "4         9.209387  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TK - Make this more obvious that it's for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_epoch_times(non_compiled_results, compiled_results, multi_runs=False, num_runs=0, save=False, save_path=\"\"):\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "    # Make both bars appear on the same plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "    # TK - make this title include dataset/model information for a better idea of what's happening\n",
    "    if multi_runs:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} ({num_runs} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    else:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    plt.legend();\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train epoch time difference: -6.234% (negative means faster)\n",
      "Mean test epoch time difference: 2.648% (negative means faster)\n",
      "[INFO] Plot saved to pytorch_2_results/figures/single_run_NVIDIA GeForce RTX 4080_ResNet50_CIFAR10_224_train_epoch_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"pytorch_2_results/figures\", exist_ok=True)\n",
    "save_path_multi_run = f\"pytorch_2_results/figures/single_run_{gpu_name}_{model_name}_{dataset_name}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "plot_mean_epoch_times(results_df, compile_results_df, multi_runs=False, save_path=save_path_multi_run, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.186983013153077, 9.430223417282104)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_epoch_time, mean_compile_test_epoch_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Save results to file with GPU details\n",
    "\n",
    "TODO:\n",
    "* Save the results to file with GPU name and other details (run on multiple machines)\n",
    "* Run for multiple passes (e.g. 5x runs to average the time over each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv',\n",
       " 'single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_non_compiled_results, save_name_for_compiled_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Try for multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    model, transforms = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.003)\n",
    "\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    return results\n",
    "\n",
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# TK - the first time you compile a model, the first few epochs will be slower than subsequent runs\n",
    "# TK - consider the first few epochs of training to be a \"warmup\" period\n",
    "# def create_and_train_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "#     model, transforms = create_model()\n",
    "#     model.to(device)\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                  lr=0.003)\n",
    "    \n",
    "#     compile_start_time = time.time()\n",
    "#     ### New in PyTorch 2.x ###\n",
    "#     compiled_model = torch.compile(model)\n",
    "#     ##########################\n",
    "#     compile_end_time = time.time()\n",
    "#     compile_time = compile_end_time - compile_start_time\n",
    "#     print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "#     compile_results = train(model=compiled_model,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             test_dataloader=test_dataloader,\n",
    "#                             loss_fn=loss_fn,\n",
    "#                             optimizer=optimizer,\n",
    "#                             epochs=NUM_EPOCHS,\n",
    "#                             device=device,\n",
    "#                             disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "#     return compile_results\n",
    "\n",
    "def create_compiled_model():\n",
    "    model, _ = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    compile_start_time = time.time()\n",
    "    ### New in PyTorch 2.x ###\n",
    "    compiled_model = torch.compile(model)\n",
    "    ##########################\n",
    "    compile_end_time = time.time()\n",
    "    compile_time = compile_end_time - compile_start_time\n",
    "    print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "    return compiled_model\n",
    "\n",
    "def train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=False):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
    "                                 lr=0.003)\n",
    "    \n",
    "    compile_results = train(model=model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=epochs,\n",
    "                            device=device,\n",
    "                            disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "    return compile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563efc283b8b475790f71c74571cd90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.8378 | train_acc: 0.7089 | test_loss: 1.0247 | test_acc: 0.6870 | train_epoch_time: 109.5564 | test_epoch_time: 9.2328\n",
      "Epoch: 2 | train_loss: 0.4580 | train_acc: 0.8411 | test_loss: 0.5060 | test_acc: 0.8253 | train_epoch_time: 109.5725 | test_epoch_time: 9.2088\n",
      "Epoch: 3 | train_loss: 0.3323 | train_acc: 0.8846 | test_loss: 0.4765 | test_acc: 0.8399 | train_epoch_time: 109.5022 | test_epoch_time: 9.1758\n",
      "Epoch: 4 | train_loss: 0.2509 | train_acc: 0.9146 | test_loss: 0.4185 | test_acc: 0.8649 | train_epoch_time: 109.5430 | test_epoch_time: 9.1935\n",
      "Epoch: 5 | train_loss: 0.1788 | train_acc: 0.9376 | test_loss: 0.4003 | test_acc: 0.8716 | train_epoch_time: 109.5906 | test_epoch_time: 9.1582\n",
      "[INFO] Run 2 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.8725 | train_acc: 0.6948 | test_loss: 0.6809 | test_acc: 0.7659 | train_epoch_time: 109.5877 | test_epoch_time: 9.2452\n",
      "Epoch: 2 | train_loss: 0.4765 | train_acc: 0.8357 | test_loss: 0.5766 | test_acc: 0.8007 | train_epoch_time: 109.4739 | test_epoch_time: 9.2453\n",
      "Epoch: 3 | train_loss: 0.3369 | train_acc: 0.8838 | test_loss: 0.3794 | test_acc: 0.8704 | train_epoch_time: 109.5909 | test_epoch_time: 9.2295\n",
      "Epoch: 4 | train_loss: 0.2466 | train_acc: 0.9138 | test_loss: 0.5049 | test_acc: 0.8333 | train_epoch_time: 109.5572 | test_epoch_time: 9.2202\n",
      "Epoch: 5 | train_loss: 0.1788 | train_acc: 0.9372 | test_loss: 0.4328 | test_acc: 0.8614 | train_epoch_time: 109.5400 | test_epoch_time: 9.2429\n",
      "[INFO] Run 3 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 0.7792 | train_acc: 0.7307 | test_loss: 0.6573 | test_acc: 0.7762 | train_epoch_time: 109.6908 | test_epoch_time: 9.2283\n",
      "Epoch: 2 | train_loss: 0.4296 | train_acc: 0.8538 | test_loss: 0.6004 | test_acc: 0.8050 | train_epoch_time: 109.5275 | test_epoch_time: 9.2120\n",
      "Epoch: 3 | train_loss: 0.3101 | train_acc: 0.8926 | test_loss: 0.4222 | test_acc: 0.8589 | train_epoch_time: 109.6433 | test_epoch_time: 9.1418\n",
      "Epoch: 4 | train_loss: 0.2354 | train_acc: 0.9186 | test_loss: 0.3736 | test_acc: 0.8787 | train_epoch_time: 109.5805 | test_epoch_time: 9.2719\n",
      "Epoch: 5 | train_loss: 0.1736 | train_acc: 0.9386 | test_loss: 0.3786 | test_acc: 0.8789 | train_epoch_time: 109.6146 | test_epoch_time: 9.2244\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "NUM_RUNS = 3\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "non_compile_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829813</td>\n",
       "      <td>0.711462</td>\n",
       "      <td>0.787613</td>\n",
       "      <td>0.743045</td>\n",
       "      <td>109.611609</td>\n",
       "      <td>9.235445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454694</td>\n",
       "      <td>0.843546</td>\n",
       "      <td>0.560969</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>109.524597</td>\n",
       "      <td>9.222032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.326421</td>\n",
       "      <td>0.887027</td>\n",
       "      <td>0.426016</td>\n",
       "      <td>0.856375</td>\n",
       "      <td>109.578773</td>\n",
       "      <td>9.182378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.915669</td>\n",
       "      <td>0.432327</td>\n",
       "      <td>0.858946</td>\n",
       "      <td>109.560207</td>\n",
       "      <td>9.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177081</td>\n",
       "      <td>0.937800</td>\n",
       "      <td>0.403896</td>\n",
       "      <td>0.870616</td>\n",
       "      <td>109.581744</td>\n",
       "      <td>9.208528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.829813   0.711462   0.787613  0.743045        109.611609   \n",
       "1    0.454694   0.843546   0.560969  0.810324        109.524597   \n",
       "2    0.326421   0.887027   0.426016  0.856375        109.578773   \n",
       "3    0.244295   0.915669   0.432327  0.858946        109.560207   \n",
       "4    0.177081   0.937800   0.403896  0.870616        109.581744   \n",
       "\n",
       "   test_epoch_time  \n",
       "0         9.235445  \n",
       "1         9.222032  \n",
       "2         9.182378  \n",
       "3         9.228536  \n",
       "4         9.208528  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.001680135726928711 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de82acde240441785f9e55049a8b9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.7646 | train_acc: 0.7342 | test_loss: 0.7037 | test_acc: 0.7672 | train_epoch_time: 122.2336 | test_epoch_time: 16.7382\n",
      "Epoch: 2 | train_loss: 0.4172 | train_acc: 0.8569 | test_loss: 0.4448 | test_acc: 0.8516 | train_epoch_time: 97.6691 | test_epoch_time: 7.5259\n",
      "Epoch: 3 | train_loss: 0.3056 | train_acc: 0.8939 | test_loss: 0.4070 | test_acc: 0.8654 | train_epoch_time: 97.6748 | test_epoch_time: 7.4222\n",
      "Epoch: 4 | train_loss: 0.2275 | train_acc: 0.9221 | test_loss: 0.4287 | test_acc: 0.8588 | train_epoch_time: 97.6403 | test_epoch_time: 7.4536\n",
      "Epoch: 5 | train_loss: 0.1673 | train_acc: 0.9409 | test_loss: 0.3591 | test_acc: 0.8873 | train_epoch_time: 97.6284 | test_epoch_time: 7.4502\n",
      "[INFO] Run 2 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.1867 | train_acc: 0.9353 | test_loss: 0.3929 | test_acc: 0.8778 | train_epoch_time: 97.7071 | test_epoch_time: 7.4878\n",
      "Epoch: 2 | train_loss: 0.1211 | train_acc: 0.9578 | test_loss: 0.3603 | test_acc: 0.8928 | train_epoch_time: 97.5929 | test_epoch_time: 7.4256\n",
      "Epoch: 3 | train_loss: 0.0917 | train_acc: 0.9682 | test_loss: 0.4029 | test_acc: 0.8845 | train_epoch_time: 97.7499 | test_epoch_time: 7.4274\n",
      "Epoch: 4 | train_loss: 0.0708 | train_acc: 0.9749 | test_loss: 0.4205 | test_acc: 0.8841 | train_epoch_time: 97.6956 | test_epoch_time: 7.4811\n",
      "Epoch: 5 | train_loss: 0.0560 | train_acc: 0.9807 | test_loss: 0.4884 | test_acc: 0.8682 | train_epoch_time: 97.8197 | test_epoch_time: 7.4636\n",
      "[INFO] Run 3 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.0706 | train_acc: 0.9757 | test_loss: 0.4214 | test_acc: 0.8836 | train_epoch_time: 97.8444 | test_epoch_time: 7.5171\n",
      "Epoch: 2 | train_loss: 0.0509 | train_acc: 0.9825 | test_loss: 0.4852 | test_acc: 0.8805 | train_epoch_time: 97.6679 | test_epoch_time: 7.5124\n",
      "Epoch: 3 | train_loss: 0.0425 | train_acc: 0.9851 | test_loss: 0.4100 | test_acc: 0.8985 | train_epoch_time: 97.6812 | test_epoch_time: 7.4985\n",
      "Epoch: 4 | train_loss: 0.0410 | train_acc: 0.9859 | test_loss: 0.4030 | test_acc: 0.9010 | train_epoch_time: 97.7047 | test_epoch_time: 7.4856\n",
      "Epoch: 5 | train_loss: 0.0394 | train_acc: 0.9864 | test_loss: 0.4396 | test_acc: 0.8923 | train_epoch_time: 97.6329 | test_epoch_time: 7.5252\n"
     ]
    }
   ],
   "source": [
    "# TK - change this to only compile a model once and then run the training loop multiple times\n",
    "# Create compiled model\n",
    "compiled_model = create_compiled_model()\n",
    "\n",
    "compiled_results_multiple_runs = []\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for compiled model\")\n",
    "    results = train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.340599</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.505985</td>\n",
       "      <td>0.842860</td>\n",
       "      <td>105.928343</td>\n",
       "      <td>10.581059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.196404</td>\n",
       "      <td>0.932397</td>\n",
       "      <td>0.430130</td>\n",
       "      <td>0.874967</td>\n",
       "      <td>97.643334</td>\n",
       "      <td>7.487950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146588</td>\n",
       "      <td>0.949077</td>\n",
       "      <td>0.406647</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>97.701943</td>\n",
       "      <td>7.449384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113085</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.417372</td>\n",
       "      <td>0.881296</td>\n",
       "      <td>97.680187</td>\n",
       "      <td>7.473454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087548</td>\n",
       "      <td>0.969324</td>\n",
       "      <td>0.429059</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>97.693671</td>\n",
       "      <td>7.479675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.340599   0.881720   0.505985  0.842860        105.928343   \n",
       "1    0.196404   0.932397   0.430130  0.874967         97.643334   \n",
       "2    0.146588   0.949077   0.406647  0.882812         97.701943   \n",
       "3    0.113085   0.960947   0.417372  0.881296         97.680187   \n",
       "4    0.087548   0.969324   0.429059  0.882582         97.693671   \n",
       "\n",
       "   test_epoch_time  \n",
       "0        10.581059  \n",
       "1         7.487950  \n",
       "2         7.449384  \n",
       "3         7.473454  \n",
       "4         7.479675  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean()\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_epoch_times(non_compiled_results, compiled_results, multi_runs=False, num_runs=0, save=False, save_path=\"\"):\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both results and compiled_results\n",
    "    # Make both bars appear on the same plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "    # TK - make this title include dataset/model information for a better idea of what's happening\n",
    "    if multi_runs:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} ({NUM_RUNS} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    else:\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {NUM_EPOCHS} | Data: {dataset_name} | Model: {model_name} | Image size: {IMAGE_SIZE} | Batch size: {BATCH_SIZE}\")\n",
    "    plt.legend();\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train epoch time difference: -9.347% (negative means faster)\n",
      "Mean test epoch time difference: -12.165% (negative means faster)\n",
      "[INFO] Plot saved to pytorch_2_results/figures/multi_run_NVIDIA GeForce RTX 4080_ResNet50_CIFAR10_224_train_epoch_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAGrCAYAAAB5SdnMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABHSUlEQVR4nO3debhd49n48e+dgZjHVBWvoNRQEYRSU5TSVqu0VTSG0FK/UqqT6BjvS19VHWi1qoOh5qJFteo1BG21KsSQoqaU1BRDSBAV7t8fzzrJzs4Z9jlJ7J19vp/rOtfZa3rWvdd4r2c9a+3ITCRJkiS1ngHNDkCSJElS50zWJUmSpBZlsi5JkiS1KJN1SZIkqUWZrEuSJEktymRdkiRJalEm61I3ImJYRExudhy1ImJ8RHyqBeIYGhH3R8SQZsfSnYj4XkQc1sM44yNi1JsTkboSEZMjYtibPM+zIuL4BsedHBE7L+yYFmXV8hzT7DgWhoj4r4iYEREDmx3LgtBK57fe7Ic9lPOHiDhwQcTUShpK1iNin4j4W0S8FBFPV58/ExFRDT8rIv5TbcTPRcT/RcT6NcOOrytvWERkRAxqcP4ZEXdHxICafsdXZQ+JiGkR8Z5Opvt+RFxSfZ59kI2IMRHxehXvjIh4JCLOjIj1eooxIsZV/bdsIO51I+LCiJgaES9GxAMR8cOIWL3B7z05Il6piXNGRLytkWkXhiqhmVnF8UxEXBYRq0bEV2rim1m3bCdFxOoR8XxEbFtT1hpVv3f1MM91qzLPreu/U0TcFxEvR8QNEbFmzbDFI+L0iHiq2h6vjIjVaoYPq6Z5uSqjzyffum2/4+/OvpbXTHXrd0ZE3N/DJGOBMzNzZjX9SRHxWLWt/ysivrrwo27Id4CvRsRifZk4IkZFxBs1y2VKRFwcEVv0ooxx9dvw/Kr2vV9ExBMRMb3alo+LiKWq4RkRb6+Z/2t12+mXa8oaX+2Pi9fNo8tje00MV0TE49X8htVNv3hE/LLaJp6MiM/Px/cdU83je3X996j6n9XXsheGnpZdH8vsOC9dVdf/3IgY12AZ81xwVGW+VLNt/Lxu+NHV+nuhWp+L0wfRy3N/q8nMRzNz6cx8fWHNIyK2qraV56LkDr+OiFVrhn8pIu6p9vlHIuJLXZSzQ7Ws+5wA123D0yNiQkTs0Ivp3/SL28x8f2aevTDnERFHRMRtEfFq/XGngfXXbX7SlR6T9Yj4AnAK5YT3VmAV4DBgG6D25HdSZi4NrA48DZzFgvU2YJ/6nlWicBFwQF3cA4F9ga5W2i1VvMsBOwOvABMi4p1dBRARAewPPAd0e+VWnST/BjwObJqZy1KW2UPAtt1NW+dD1cGh4+/xXkzLQjgoHlEtt7cDSwMnZ+a3OuKjbBu31MS7UWZOAY4Bfh5zamF/Skn0/tbD/E4D/l7bIyJWBi4Dvg6sCNxG2QY6HAVsDQynbDfTgB/WDL8AuANYCfgqcElEDO3NQqhzUt062mQ+ymq2I2q+xzu6Gqk6WR8I1CagvwDWr7b1dwOfiIiPNDLThXnyzswngPuA3eejmMer7XsZYKuqvJsjYqcFEGKvRcSKwC3AEsDWmbkM8F5geWCdLia7qG47PakqaxiwHZB0vow6ju2rAf+mrOcObwBXAx/tYp7jgHWBNYEdgS9HxPsa/JqdeQjYu257OQD453yUuTB1t+zmx1YRsc0CKqvDJjXbxuw7dxGxK+XCfCdgGLA2cNwCnrfmWAE4g7Ks1wSmA2fWDA/KNr8C8D7giIiYKzeKiMGUvK2n82sjOrbh5YCfAJdFm9xZmA+PA8cDv+xkWE/rr6f8pFPdJusRsRzw38BnMvOSzJyexR2ZOTozX62fJjNfBs4Hukx6++gk4LguTupnAx+NiCVr+u1K+X5/6K7QzHw9Mx/KzM8AN1JOLl3ZjrJwjwL2ie5r6sYBf87Mz1fJKpn5dGb+IDMv7BgpIj4YEROj3B34S0QM7y7eaprFI+IHVW3W49Xnxatho6LU/B0TEU8CZ0bEwCi13w/VXB2vUY2/fs1V4P0R8fGe5l99l2nAb4ERjYwP/Ax4AvhmlFtU7wC+1sP33IeyIV9XN+gjwKTM/HV1sTYO2KSm1mot4I+Z+VQ1/EJgo6rM9YDNgG9m5iuZeSlwN10nG31WU4t0aLWenqgufjuGd7keq+EfrraNF6t1V5vkrBkRf67W5zXVBQxR7jSdGxHPVtvU3yNilQX93YB3AdM6tm2AzLw/M1+qGecNykXdPLrYTsdExJ/qxqutHT4rIk6LiKuq7/23iFinGhZR7qQ9HaX27666C+/xwG7z+6Wr49+UzPwG8HPg2zWxnhJz7ixMiIjtqv7vA75CSTJn33mJiIMi4t7quzwcEZ/uRSifp5wE9svMyVVsj2XmUZl5Vy+/1gHAXykVLF1WQmTmK8DF1Ozz1T72Y+ouqOvK/p/MfD4z76UcB8b0Mr5aT1L2111h9kXLu4ErakeKiN2j3NWbFuWuwQY1wzaNiNur5X4RMKRu2l4fk3vS2bKLiLdFxKVRat8eiYgja4ZtGaXm7sUoNXDfqyvyJEqy0KmuvkNE/Ar4L+DKqLu70o0DgV9k5qTMfB74H+ZvHdbGeVZE/DhK04UZ1THtrdWx8Pkod4s2rRl/bM157B8RsWfNsIER8d0od30fiVL7ObsWPyKWizl3ov4d5e58p0lnV8s/au4MRMTWMfedqplRNSmJiAE1sT4b5U7cio0sk8z8Q3Vue7HKp35EqejrGH5SZt6embMy837g8trhlS8A11AqFRaIzHyDktutSKm0JSLWiYjrq+/4TEScFxHLV8M63dYiYttqm5xWHS/H1Mxmhc6O7/Wim/Nc1DQTjYg769ZRRtXcMUoNeEccd0YvmkFm5mWZ+Vvg2U6Gdbv+6CY/6U5PNetbA4tTNoaGRMTSwGhKzWWj0/w4In7cw2iXAS/SyUEiM/9CSQRra/H2B87PzFmNxlHNY7tuhh8IXMmcWtwPdjPuzsCl3c0sIjajXJl9mlLL+1Pgiuj5FuNXKbV7I4BNgC2ZO/F9K2WHWhM4lHJi3xf4ALAscDDwcpTb5f9H2QHfUo3z44joccOJiJUoy/vBnsaFkuQAnwI+A/wAOKTakLsqf1nKheIXOhm8ETC7qUmVID7EnA3+F8A21clwScr2+IeaaR/OzOk15d1JAzvLfNiRUru4CzA25twW7HI9RmlmdQ7wJUpt6fbA5JoyPwEcRFlviwFfrPofSKkBWYOyTR1GuWvUcaL7XQ+x/m910P1zDwevjYF5mslU85gBTAGWomxbXanfThuxL6VWbwXKtndC1X8XyjJaj7K89mbuA+m9lGW8IF0GbFbtR1AS1hGU73Q+8OuIGJKZVwPfYk7NdkccT1OOIctS1uX3q2MCANVJpKu7cDsDl1Un0Pl1AHBe9bdrdHFxV33PfWlwn4+IFSiVG7XNwhbEvnYOc+6k7kM5P82uOIpyQX4B8DlgKPB7SsKwWJQKlt8Cv6Ksp19Tc6Hem2NylXRMayTg+mUXpUnnlZTlsRql1vpzUWqxodSKnlLdpVqHkujXOg1YLzppYtDdd8jM/YFHmXPH9qSaSW+K0tTlspi7OdNcx9vq8yrVOWBB+DjluLcyZT3eAtxedV8C1F6oPEQ5Ry9HOQ6cG3OaGBwCvJ+yD24G7FE3n7OBWZQKhE0px4yunv3pafmTmbPvIFOOR3+lbHcAR1bz34GyDzxPWWcARKlM+EQX8663PTCpswEREZTlMamm35qUc/x/N1h+Q6oLmwOAR4CnOnoD/0v5jhtQzjvjADrb1iLivyjn4h9S9s0RwMSa2XR1fK/X5XmuVmZuUrOOPk85Z90epdnJVZQL3hUp589Lo7rD3uC5slH166+7/KRrmdnlH7Af8GRdv79QajtfAbav+p0FzKz6P0mp5VinZtjxdWUMo9xyHdTd/GvGT8oO9gHKyl+cspDPqhnna8A11edlgZcpzU86hk8Gdq4+jwH+1Ml83ge81lmMwJKUi4U9qu6fApd3E/Ms4H013UdUy2cG8LOq308otU61090P7FAT84xqumnAb6v+DwEfqJlmV2By9XkU8B9gSF2ZH+4kxr2Bm+v6/ZRS69zZdxpfLdcXqmUzEfivunE6XbbVsEGUpOlfPa17ysHymOrzOODcmmG/AE6sG//PwJia9X9BFeMsyoXjitWw/YG/1k17Qu221Mm2OrmbOM9izrbf8Xd23Ta0fs34J1FqqXpajz8Fvt/NevhaTfdngKurzwdT9tHhjexbdeW+i9LMo6OJy3Sq/biTcb8KXNjFsKCcDI8DlulinM6203m2nWr5vb1mWf+8ZtgHgPuqz++hNIXYChjQyfzeS7lI6+q7jwdGdRPrlE76r1/Ft1oX0z1PaVowzzbcxfi/BY5qcF09ABzWwzi1y25ctbxrt9O3UZrkvQasXI13H3B0F9v3G5QT9TzbFmXfTmBYTb81qn616/i9dL8/Ta4to27YGOBPlKY/T1FO1n+l1FrNPh9QmsddXDPdAEoTlFGUE+fjQNQM/wvVOYrGjsk7N7iOulx2lH3t0brxj6U0DQS4ibL/rFw3zrBqmQ6i7Pd/rfqfC4zr63eolstilAvdHwH3MOfc9xBzn8sG16/rTr73mC6GzY6/Ztyf1Qz/LHBvTffGlDt4XS3jiVTnNuB64NM1w3auWVarUC4ElqgZvi9wQxfl9rj86/r/hJL8Dai67wV2qhm+KmU/ayjnqZluOKXZ7XZdDD+OcvG0eE2/y4G9a5bv8d2UP4zGz28zq7/R3Yy/B3BHTfdc2xplG/9NN/Pq9Pjeybhdnucox/JP1fXbllI5sl7VfQzwq7px/ggc2Mv1M1ce2sj6o5v8pLu/nmrWnwVWjpqmJ5n57sxcvhpWO/3Jmbl8Zr41M3fPzIeq/rMoO3etwZSDV69qhTLz95RkvbNauHOAHasrpo8BD2bmHb0pn1LD8VwXw/akfJffV93nAe+Prts6P0vZQTti/1G13H7AnOWxJvCFqgZtWlVLswblJNphj2q5Lp+Ze1T93kZJeDv8q26aqVk99FdZg3LArbcm8K66+Y+m1Hh25cjMXI6yEa5AeUahUWMpy+Vp5tQEzyMiRlAOtN/vYpQZlA2+1rKU5BLKgXMI5Yp7KUoN6B8anLYvTq5ZR8tn5oF1wx+r+Vy7rrpbj12tsw5P1nx+mfL8AJQawz8CF0ZpWnNSlPaLPcrMv2Vp6vZqlgd0/kw5YHbmeUpi31k5We17r9B929b67bQRnX7vzLyekmScBjwVEWdUd2c6LEM54SxIq1EOuNOgPN8TpVnLC9W+tByldrBTEfH+iPhrlCZo0yjLusvx68x1fGnQxXXb6eOUi7JrMvOZapzzmbcpzMnVsWsYZZ12+SxDnRnV/9r1ML/7GlmalFxFVRubmX+uG2Wu/SrL3YfHKOvrbcC/szprVmr3wUaOyb3R1bJbE3hb3Xy+QtW8APgk5S7RfdUt/s7u4v6MUsP9obr+vf4OmXlTZv4nS/PGoyi36juaDtUfMzs+z9d6rPFUzedXOunuOLYREQfEnOY90yjNbTv2mbcx97G29vOalPPuEzXT/pRyZ7IzjSz/jpg+TbkQ/ETOudO1JvCbmnndC7zOnPXboyjN//5AuYC/uZPhR1BqunfLqklytS0sk5kX1Y8/Hzq24SWAkcB3IuL91fzeEuUlGv+OiBcpF43dHcP6el6r1/B5LkqT34spiXjHsy1rAnvV7SPb0vtjape6WX/d5Sdd6ilZv4VyNfrhPkVbPEo5UNVaC3gs+3YL92uUWr3a9ulk5qPAzZRkc39K8t5be1ZldOZAyobzaJQ2tr+m7Pz7djH+dczdLKczjwEn1J1Al8zMC3qY7nHKxtbhv6p+HXLu0XmMzh86ewy4sW7+S2fm/+th/mTm3ZSrytOqW3HdiogNKU06PkU5EH4lItbtYvRRlG2mY1l/kfJMwu3V8EnUNGmobjGvw5xbTZtQrnafqw5iPwS2jNKuexKwdkTUJpqb0MVtxgVkjZrPteuqu/XY1TrrVma+lpnHZeaGlLa8H6Tu4eveFEepJe/MXZSTWXcG0f13qN9OX6Jmv46I7i4a5y0s89TM3Jxy2349yvbWYQPmvpW/IOwJ3J6ZL0Vpn34M5Zb+CtXJ7QXmLL+5vmvVrOJS4GRglWr839P18q53LbBn1Lwhq7ciYokq3h2q5g9PAkdTnv/YpH786hh7FHBKNW23srRvfoK5mx8tqH3tHEoTuV91Mmyu/ao6Pq1BqV1/Alit7pj1XzWf+3pM7lYny+4x4JG6+SyTmR+oxn8gM/elJJPfpjwEv1Rdma9RLob/h7m3m56+Q/1+12nINWXOdbytPj+VmfO0112YquYdP6PcpV6p2mfuqYnzCeauPKo97j5GyWVWrlkmy2Zmp02yGln+VUzbUZb/hzPzhbr5vb9uHQzJzH/34rteS7lDMs82HhEHUz30mzXPDVGaU42s2Z/3pjSvargpc1eqSph7KJU4Hc///C9lWxmepcnQfsy9LTaai/Q2lobOc9W+9lvgB5lZmxA/RqlZr10/S2XmifMbWzXf7tZfd/lJl7o90FdX2cdR2jF/LCKWjvLgxAjKFUEjLgV2i4hdojwA8jZKwn1hD9N1FdN4ygNG9bU/UNqkHUG5LXpeI+VVMa0VET+kJInz1ARWtfU7UTaIEcxpY/ztLuKActt5uyjveF6tKmdl5tRWQDnwHBYR74piqYjYrS6R7MwFwNeivOd6ZeAbzP1Wjno/B/4nymsQIyKGR2lv+DtKu8f9I2Jw9bdF1DyM1YOzKQezbt+yUSUUv6A8VX5flgfgTgXO6CLRP4OyQ4+o/k6n1KR1tOf8DfDOiPholLfLfAO4KzM7Hqb5O3BAlAeKBlNuFz+emc9UV9YTKQ+6DonygNJweni+YD59PSKWjPIswEHMeeahu/X4C+CgKK+oHBARq0UDr32LiB0jYuMo7QtfpNx67fE1YxGxfETsWi2TQRExmnJr/I9dTHIrsHzNtj0gIj4dEStU29iWwOHM+3Bwd+4ENoqIEdV6HdfohNV2+65qfb9EuV1b+713oJF2gT3PJ6p18U3KhedXqkHLUO68TQUGRcQ3mLs28ilgWE1yvRiludFUYFaUmqpdehHK96ryz65ODFRxfS8afyByD8oy2pA5+9oGlAqLTi/wMvP/KMnw7Lub1brqaNO9eMz93v1zKNv4CtX2ewgL5k1hN1Ka1HT2FoWLKeecnart4QuURO0vlAqoWcCR1Xb+EcqzIh36ekzuUd2yuxV4McoD1ktU56F3RvU60IjYLyKGVhVa06oiOtuPf0VZ9rUPn/f0HZ6ivNGFal4d+9zAKM+cfZdyYXNvNco5wCcjYsMozyF8jQX/trdGLEVJ/qZCeUCbuV9kcTFwVLUfLE+5eAZmvxHqGuC7EbFsdbxaJ7p4DWEjyz9Kje1FwAE1NbYdTgdOqNk3h0ZEQ5We1TH1euC0zDy9k+GjKc/AvDczH64b/HVKRcWI6u8KyvZwUCPzbiC29Sk10B0X3MtQNdWt4q5/jeRc2xolL9s5Ij5e7X8rRcknextHo+e5X1Ka0pxU1/9c4EPVOW9gdd4bFY2/VntQdZwbCHRM3/Egc7frj27yk25nmo21yxlNObi8TNlR/kY54CyWjbWL+hAwgVLT9C/KayBr246dDpzezfRJ1fay6n5X1e+suvGWotya+0MnZUxm7jbrr1M2speqmM4GNqgZfxhz2ruNBSZ0UubbKBvJO7uIe33KAeSZKq77KSeXNWrGeV+18qZRagZ+TdXOly7aR1JuoZxajf9E9XlINWwUde1rKRvU1yhtJqdX81u9GvYOSiI8lXJr/XpgRBffZzzztgU7BritpnsM87Y7PpqSiA2u6bc45WRwSAPb3zjq2vtSmsncR7lNOp6528quRDkoPF0t1z8BW9at2/HVtPd3tozrxp3czfCzKG2BZ9T8PVO3DR1KOUk/CXy5kfVYDd+TUoM9nfKwza6drYfaZU6503M/Zbt+qiqzo33oV+hk36iGDa22i+nVMvsr5WTQ3Xr5DnOeKxhAeYXfc9Uy+Gc1v+hi2lF03g78q5T95TFKLc3sfZ+640xtGZSL6bs6ln+1/peuhq1KeeB1sW6+y3i6b7P+BnOOF49THnzbqm4f+wXlxPEE8GXmPuasRNkOn6fUxkO5mHmqWt6/olRg1H6/GXTRVrXm+PPLaruaTtkfvgksWQ2vXXbjmHcfuhr4biflfrwqc1D9Mq+G701J5havmc9cf3X7+S+r5fIU8PketqnJ9NBmvYth9c8w7Qn8g3LOuRHYqGbYSEo70emUZOuiuuXe0DGZ8mDfjB6ODV0uu2r9XVAt6+cp+1xH2edSjl8zKInRHnXHlEE1ZX686jeuwe/wYcod72mUu5bvYc4x42lKTeS6dXF/vlp/L1JeQ7d4D997TBfD5oq/fhlRLoDH13S/HZhV030C5RjzDOWC9UaqYyFle/0+5Tz2COW88xrVMYg5rx6cUm0XdwD7dBFnj8ufsj12HBc6/ibVHA87HmicTmn68a2a8ifRRdtvyj6cdeXOqBn+SPW9aod3mj/VL98u1kej57eXqu3mW8xpm78RJbebQakE+wI1x/X6ba1mv/lbtS09RtVOvJNtYRSdnCOqYd2d58bXbBNJyVtrl9V21bB3VdvPc5T85yqqZ/Do5lxZDR/HvMe9cQ2uv27zk67+OjZiSZ2I8laE8Zk5rI/TPkK5SOnNW4kWCVGe17iZ8iD3PE/it4qI+C7wUJZXDHY1znjKwXb8mxWX5hXl1XejsnodpRY9UX4kZnxmntXkON5PSWLXbGYcrWx+zm96cy20HyKR1N4ycyrl7lFLy8zOXv8pqY1EaZ+8I6W5yyqUGs7fNDUoaQHp88NJUj8xjfIGH7W3s5j7PfZqjh+w4N/aozfXb5n73dlvlqA8c/Y8pYnLvZTngNS1aXh+WyTYDEaSJElqUdasS5IkSS3KNutNtPLKK+ewYcOaHYYkSVKPJkyY8ExmdvVjkFpITNabaNiwYdx2223NDkOSJKlHEfGvnsfSgmYzGEmSJKlFmaxLkiRJLcpkXZIkSWpRtlmXJKkNvfbaa0yZMoWZM2c2OxQtYoYMGcLqq6/O4MGDmx2KMFmXJKktTZkyhWWWWYZhw4YREc0OR4uIzOTZZ59lypQprLXWWs0OR9gMRpKktjRz5kxWWmklE3X1SkSw0koreUemhZisS5LUpkzU1RduN63FZF2SJElqUbZZlySpHxg29qoFWt7kE3dboOVJ6pw165IkST34wAc+wLRp0wBYeumlezXtuHHjOPnkkxdCVN3riHPy5Mmcf/75b/r8tWCYrEuSJPXg97//Pcsvv/xCn8+sWbMWeJkm64s2k3VJkrRQTJ48mQ022IBDDjmEjTbaiF122YVXXnmFiRMnstVWWzF8+HD23HNPnn/+eQBGjRrFMcccw5Zbbsl6663HzTff3GXZr7/+Ol/84hfZeOONGT58OD/84Q8BuO6669h0003ZeOONOfjgg3n11VcBGDZsGF/5ylfYeuutGTlyJLfffju77ror66yzDqeffjoA48ePZ/vtt2fPPfdkww035LDDDuONN96YPf0zzzwzTxzf+c532GKLLRg+fDjf/OY3Z/c/4YQTeMc73sHOO+/M/fff3+1yGjVqFF/5ylfYYYcdOOWUU5gwYQI77LADm2++ObvuuitPPPEEAKeeeiobbrghw4cPZ5999gHmrbV/5zvfyeTJk+cqf+zYsdx8882MGDGC73//+0yaNIktt9ySESNGMHz4cB544IFu41NzmaxLkqSF5oEHHuDwww9n0qRJLL/88lx66aUccMABfPvb3+auu+5i44035rjjjps9/qxZs7j11lv5wQ9+MFf/emeccQaPPPIId9xxB3fddRejR49m5syZjBkzhosuuoi7776bWbNm8ZOf/GT2NGussQa33HIL2223HWPGjOGSSy7hr3/9K9/4xjdmj3Prrbfy3e9+l7vvvpuHHnqIyy67rMsYrrnmGh544AFuvfVWJk6cyIQJE7jpppuYMGECF154IXfccQeXXXYZf//733tcTtOmTePGG2/kyCOP5LOf/SyXXHIJEyZM4OCDD+arX/0qACeeeOLs79txgdGIE088ke22246JEydy9NFHc/rpp3PUUUcxceJEbrvtNlZfffWGy9KbzwdMJUnSQrPWWmsxYsQIADbffHMeeughpk2bxg477ADAgQceyF577TV7/I985COzx62vIa517bXXcthhhzFoUEllVlxxRe68807WWmst1ltvvdlln3baaXzuc58DYPfddwdg4403ZsaMGSyzzDIss8wyDBkyZHZ79C233JK1114bgH333Zc//elPfOxjH+s0hmuuuYZrrrmGTTfdFIAZM2bwwAMPMH36dPbcc0+WXHLJuebbnb333huA+++/n3vuuYf3vve9QLmDsOqqqwIwfPhwRo8ezR577MEee+zRY5ld2XrrrTnhhBOYMmUKH/nIR1h33XX7XJYWPmvWJUnSQrP44ovP/jxw4MDZSXFP4w8cOLDb9tuZOc/7wDOzobIHDBgwV1wDBgyYPa/6Mrt753hmcuyxxzJx4kQmTpzIgw8+yCc/+ckep+vMUkstNbvMjTbaaHaZd999N9dccw0AV111FYcffjgTJkxg8803Z9asWQwaNGh2Ux2goR8z+sQnPsEVV1zBEksswa677sr111/fq1j15rJmXZKkfqBVXrW43HLLscIKK3DzzTez3Xbb8atf/Wp2LXtv7LLLLpx++umMGjWKQYMG8dxzz7H++uszefJkHnzwQd7+9rf3qexbb72VRx55hDXXXJOLLrqIQw89tMtxd911V77+9a8zevRoll56af79738zePBgtt9+e8aMGcPYsWOZNWsWV155JZ/+9Kcbmv873vEOpk6dyi233MLWW2/Na6+9xj//+U822GADHnvsMXbccUe23XZbzj//fGbMmMGwYcP43e9+B8Dtt9/OI488Mk+ZyyyzDNOnT5/d/fDDD7P22mtz5JFH8vDDD3PXXXfxnve8p1fLSW8ek/U2t6Dfq6vGtcqJUZJazdlnn81hhx3Gyy+/zNprr82ZZ57Z6zI+9alP8c9//pPhw4czePBgDjnkEI444gjOPPNM9tprL2bNmsUWW2zBYYcd1qtyt956a8aOHcvdd989+2HTruyyyy7ce++9bL311kB5VeK5557LZpttxt57782IESNYc8012W677Rqe/2KLLcYll1zCkUceyQsvvMCsWbP43Oc+x3rrrcd+++3HCy+8QGZy9NFHs/zyy/PRj36Uc845hxEjRrDFFlvMbgJUa/jw4QwaNIhNNtmEMWPGMHPmTM4991wGDx7MW9/61rna7Kv1RE+3jLTwjBw5Mm+77baFOg+T9eYxWZfUTPfeey8bbLBBs8NYpIwfP56TTz55dk11f9bZ9hMREzJzZJNC6rdssy5JkiS1KJvBSJKklvXHP/6RY445Zq5+a621Fr/5zW8W+LxGjRrFqFGjFni5HQ4//HD+/Oc/z9XvqKOO4qCDDlpo89Siz2RdkiS1rF133ZVdd9212WEsEKeddlqzQ9AiyGYwkiRJUosyWZckSZJalMm6JEmS1KJssy5JUn8wbrkFXN4LC7Y8SZ2yZl2SJC3SvvGNb3DttdcC5Y0uvfkNk/Hjx/PBD35wYYXWpdo4v/Wtb73p89eiw2RdkiQt0v77v/+bnXfeeaHPZ9asWQulXJN1dcdkXZIkLRTnnHMOw4cPZ5NNNmH//ffnX//6FzvttBPDhw9np5124tFHHwVgzJgx/L//9//YcccdWXvttbnxxhs5+OCD2WCDDRgzZszs8pZeemm+8IUvsNlmm7HTTjsxderU2dNfcskl88z/mmuuYeutt2azzTZjr732YsaMGQBcffXVrL/++my77bZcdtll3X6HcePGceihh7LLLrtwwAEHMHXqVD760Y+yxRZbsMUWW8x+b/qNN97IiBEjGDFiBJtuuinTp0+fp9b+iCOO4Kyzzpqr/LFjx/LKK68wYsQIRo8ezUsvvcRuu+3GJptswjvf+U4uuuiiXi93tReTdUmStMBNmjSJE044geuvv54777yTU045hSOOOIIDDjiAu+66i9GjR3PkkUfOHv/555/n+uuv5/vf/z4f+tCHOProo5k0aRJ33303EydOBOCll15is8024/bbb2eHHXbguOOO63L+zzzzDMcffzzXXnstt99+OyNHjuR73/seM2fO5JBDDuHKK6/k5ptv5sknn+zxu0yYMIHLL7+c888/n6OOOoqjjz6av//971x66aV86lOfAuDkk0/mtNNOY+LEidx8880sscQSDS2nE088kSWWWIKJEydy3nnncfXVV/O2t72NO++8k3vuuYf3ve99DZWj9mWyLkmSFrjrr7+ej33sY6y88soArLjiitxyyy184hOfAGD//ffnT3/60+zxP/ShDxERbLzxxqyyyipsvPHGDBgwgI022ojJkycDMGDAAPbee28A9ttvv7mmr/fXv/6Vf/zjH2yzzTaMGDGCs88+m3/961/cd999rLXWWqy77rpEBPvtt1+P32X33XefnXxfe+21HHHEEYwYMYLdd9+dF198kenTp7PNNtvw+c9/nlNPPZVp06YxaFDf3uGx8cYbc+2113LMMcdw8803s9xyC/jBYC1yfBuMJEla4DKTiOh2nNrhiy++OFAS8o7PHd1dtRXvrvzM5L3vfS8XXHDBXP0nTpzYY1z1llpqqdmf33jjDW655ZZ5as7Hjh3Lbrvtxu9//3u22morrr32WgYNGsQbb7wxe5yZM2f2OK/11luPCRMm8Pvf/55jjz2WXXbZhW984xu9ilftxWRdkqT+4E1+1eJOO+3EnnvuydFHH81KK63Ec889x7vf/W4uvPBC9t9/f8477zy23XbbXpX5xhtvcMkll7DPPvtw/vnndzv9VlttxeGHH86DDz7I29/+dl5++WWmTJnC+uuvzyOPPMJDDz3EOuusM08y35NddtmFH/3oR3zpS18CSvI/YsQIHnroITbeeGM23nhjbrnlFu677z4233xz/vGPf/Dqq68yc+ZMrrvuuk5jHjx4MK+99hqDBw/m8ccfZ8UVV2S//fZj6aWXnqeNu/ofk3VJkrTAbbTRRnz1q19lhx12YODAgWy66aaceuqpHHzwwXznO99h6NChnHnmmb0qc6mllmLSpElsvvnmLLfcct0+fDl06FDOOuss9t13X1599VUAjj/+eNZbbz3OOOMMdtttN1ZeeWW23XZb7rnnnoZjOPXUUzn88MMZPnw4s2bNYvvtt+f000/nBz/4ATfccAMDBw5kww035P3vfz+LL744H//4xxk+fDjrrrsum266aadlHnrooQwfPpzNNtuMAw44gC996UsMGDCAwYMH85Of/KRXy0jtJzKz2TH0WyNHjszevAu2L4aNvWqhlq+uTT5xt2aHIKkfu/fee9lggw2aHcYCtfTSS89+o4sWrs62n4iYkJkjmxRSv+UDppIkSVKLshmMJElaJCzMWvUzzzyTU045Za5+22yzDaeddtpCm6fUCJN1SZLaVCNvZFFx0EEHcdBBBzU7jJZgE+nWYjMYSZLa0JAhQ3j22WdNvNQrmcmzzz7LkCFDmh2KKtasS5LUhlZffXWmTJnC1KlTmx2KFjFDhgxh9dVXb3YYqpisS5LUhgYPHsxaa63V7DAkzSebwUiSJEktymRdkiRJalEm65IkSVKLMlmXJEmSWpTJuiRJktSiTNa7EBG/jIinI+Kemn4rRsT/RcQD1f8VaoYdGxEPRsT9EbFrc6KWJElSOzFZ79pZwPvq+o0FrsvMdYHrqm4iYkNgH2CjapofR8TANy9USZIktSOT9S5k5k3Ac3W9PwycXX0+G9ijpv+FmflqZj4CPAhs+WbEKUmSpPZlst47q2TmEwDV/7dU/VcDHqsZb0rVbx4RcWhE3BYRt/mrcpIkSeqOyfqCEZ30y85GzMwzMnNkZo4cOnToQg5LkiRJi7JBzQ5gEfNURKyamU9ExKrA01X/KcAaNeOtDjz+pken1jJuuWZH0H+Ne6HZEUiStEBYs947VwAHVp8PBC6v6b9PRCweEWsB6wK3NiE+SZIktRFr1rsQERcAo4CVI2IK8E3gRODiiPgk8CiwF0BmToqIi4F/ALOAwzPz9aYELkmSpLZhst6FzNy3i0E7dTH+CcAJCy8iSZIk9Tc2g5EkSZJalMm6JEmS1KJM1iVJkqQWZbIuSZIktSiTdUmSJKlFmaxLkiRJLcpkXZIkSWpRJuuSJElSizJZlyRJklqUybokSZLUokzWJUmSpBZlsi5JkiS1KJN1SZIkqUWZrEuSJEktymRdkiRJalEm65IkSVKLMlmXJEmSWpTJuiRJktSiTNYlSZKkFmWyLkmSJLUok3VJkiSpRZmsS5IkSS3KZF2SJElqUSbrkiRJUosyWZckSZJalMm6JEmS1KJM1iVJkqQWZbIuSZIktSiTdUmSJKlFDWp2AAtbRLwF2AZ4G/AKcA9wW2a+0dTAJEmSpB60bbIeETsCY4EVgTuAp4EhwB7AOhFxCfDdzHyxaUFKkiRJ3WjbZB34AHBIZj5aPyAiBgEfBN4LXPpmByZJkiQ1om2T9cz8UkQMiIiPZ+bFdcNmAb9tTmSSJElSY9r6AdOqXfpnmx2HJEmS1BdtnaxXromIL0bEGhGxYsdfs4OSJEmSetK2zWBqHFz9P7ymXwJrNyEWSZIkqWFtn6xn5lrNjkGSJEnqi7ZvBhMRS0bE1yLijKp73Yj4YLPjkiRJknrS9sk6cCbwH+DdVfcU4PjmhSNJkiQ1pj8k6+tk5knAawCZ+QoQzQ1JkiRJ6ll/SNb/ExFLUB4qJSLWAV5tbkiSJElSz9r+AVNgHHA1sEZEnAdsAxzU1IgkSZKkBrR9sp6Z10TEBGArSvOXozLzmSaHJUmSJPWo7ZvBRMR1mflsZl6Vmb/LzGci4rpmxyVJkiT1pG1r1iNiCLAksHJErMCch0qXBd7WtMAkSZKkBrVtsg58GvgcJTGfwJxk/UXgtCbFJEmSJDWsbZP1zDwFOCUijszMU2uHRcTiTQpLkiRJaljbt1kHxnTS75Y3OwhJkiSpt9q2Zj0i3gqsBiwREZsyd5v1JZsWmCRJktSgtk3WgV0pteqrA9+r6f8i8JVmBCRJkiT1Rtsm65l5NnB2RHw0My9tdjySJElSb/WHNut/johfRMQfACJiw4j4ZLODkiRJknrSH5L1M4E/Mufd6v+kvNJRkiRJamn9IVlfOTMvBt4AyMxZwOvNDUmSJEnqWX9I1l+KiJWABIiIrYAXmhuSJEmS1LO2fcC0xueBK4B1IuLPwFDgY80NSZIkSepZ2yfrmXl7ROwAvIPyrvX7M/O1JoclSZIk9ajtk/WIGAJ8BtiW0hTm5og4PTNnzkeZRwOfqsq7GziI8kNLFwHDgMnAxzPz+fkKXpIkSf1af2izfg6wEfBD4EfAhsCv+lpYRKwGHAmMzMx3AgOBfYCxwHWZuS5wXdUtSZIk9Vnb16wD78jMTWq6b4iIO+ezzEHAEhHxGqVG/XHgWGBUNfxsYDxwzHzOR5IkSf1Yf6hZv6N6AwwAEfEu4M99LSwz/w2cDDwKPAG8kJnXAKtk5hPVOE8Ab+ls+og4NCJui4jbpk6d2tcwJEmS1A+0bbIeEXdHxF3Au4C/RMTkiHgEuAXYfj7KXQH4MLAW5YeWloqI/RqdPjPPyMyRmTly6NChfQ1DkiRJ/UA7N4P54EIqd2fgkcycChARlwHvBp6KiFUz84mIWBV4eiHNX5IkSf1E2ybrmfmvhVT0o8BWEbEk8AqwE3Ab8BJwIHBi9f/yhTR/SZIk9RNtm6wvLJn5t4i4BLgdmAXcAZwBLA1cHBGfpCT0ezUvSkmSJLUDk/U+yMxvAt+s6/0qpZZdkiRJWiDa9gHTDhGxVEQMqD6vFxG7R8TgZsclSZIk9aTtk3XgJmBI9WNG11F+bfSspkYkSZIkNaA/JOuRmS8DHwF+mJl7Un7FVJIkSWpp/SJZj4itgdHAVVU/2+pLkiSp5fWHZP1zwLHAbzJzUkSsDdzQ3JAkSZKknrV9DXNm3gjcWNP9MHBk8yKSJEmSGtO2yXpE/CAzPxcRVwJZPzwzd29CWJIkSVLD2jZZB35V/T+5qVFIkiRJfdS2yXpmTqj+39jTuJIkSVIr6g8PmEqSJEmLJJN1SZIkqUW1dbIeEQMj4jvNjkOSJEnqi7ZO1jPzdWDziIhmxyJJkiT1Vts+YFrjDuDyiPg18FJHz8y8rHkhSZIkST3rD8n6isCzwHtq+iVgsi5JkqSW1vbJemYe1OwYJEmSpL5o6zbrABGxXkRcFxH3VN3DI+JrzY5LkiRJ6knbJ+vAz4BjgdcAMvMuYJ+mRiRJkiQ1oD8k60tm5q11/WY1JRJJkiSpF/pDsv5MRKxDeaiUiPgY8ERzQ5IkSZJ61vYPmAKHA2cA60fEv4FHgNHNDUmSJEnqWdsn65n5MLBzRCwFDMjM6c2OSZIkSWpE2zeDiYiHIuI8YH9gjWbHI0mSJDWq7ZN1YEPgp8BKwMkR8XBE/KbJMUmSJEk96g/J+uuU1za+DrwBPAU83dSIJEmSpAa0fZt14EXgbuB7wM8y89kmxyNJkiQ1pD/UrO8L3AR8BrgwIo6LiJ2aHJMkSZLUo7avWc/My4HLI2J94P3A54AvA0s0My5JkiSpJ21fsx4Rl0bEQ8ApwNLAAcAKzY1KkiRJ6lnb16wDJwK3Z+brzQ5EkiRJ6o3+kKxPBA6PiO2r7huB0zPzteaFJEmSJPWsPyTrPwEGAz+uuvev+n2qaRFJkiRJDegPyfoWmblJTff1EXFn06KRJEmSGtT2D5gCr0fEOh0dEbE25QeSJEmSpJbWH2rWvwTcEBEPAwGsCRzU3JAkSZKknrV9sp6Z10XEusA7KMn6fZn5apPDkiRJknrUtsl6RHyki0HrRASZedmbGpAkSZLUS22brAMf6mZYAibrkiRJamltm6xnpu3SJUmStEjrD2+DkSRJkhZJJuuSJElSizJZlyRJklpUv0vWI2JkRKzW7DgkSZKknvS7ZB34LPC7iLio2YFIkiRJ3Wnbt8F0JTMPBIiIZZodiyRJktSdtq9Zj4htImKp6vN+EfG9iFgzM6c3OzZJkiSpO22frAM/AV6OiE2ALwP/As5pbkiSJElSz/pDsj4rMxP4MHBKZp4C2ARGkiRJLa8/tFmfHhHHAvsB20fEQGBwk2OSJEmSetQfatb3Bl4FPpmZTwKrAd9pbkiSJElSz9q+Zr1K0L9X0/0otlmXJEnSIqBtk/WImA5kV8Mzc9k3MRxJkiSp19o2Wc/MZQAi4r+BJ4FfAQGMxgdMJUmStAjoD23Wd83MH2fm9Mx8MTN/Any02UFJkiRJPekPyfrrETE6IgZGxICIGA283uygJEmSpJ70h2T9E8DHgaeqv72qfpIkSVJLa9s26x0yczLlB5EkSZKkRUrbJ+sRMRQ4BBhGzffNzIPno8zlgZ8D76S8ceZg4H7gomo+k4GPZ+bzfZ2HJEmS1B+awVwOLAdcC1xV8zc/TgGuzsz1gU2Ae4GxwHWZuS5wXdUtSZIk9Vnb16wDS2bmMQuqsIhYFtgeGAOQmf8B/hMRHwZGVaOdDYwHFth8JUmS1P/0h5r130XEBxZgeWsDU4EzI+KOiPh5RCwFrJKZTwBU/9/S2cQRcWhE3BYRt02dOnUBhiVJkqR20x+S9aMoCfvMiJhe/b04H+UNAjYDfpKZmwIv0YsmL5l5RmaOzMyRQ4cOnY8wJEmS1O7aPlnPzGUyc0BmDqk+L5OZy85HkVOAKZn5t6r7Ekry/lRErApQ/X96/iKXJElSf9f2yTpAROweESdXfx+cn7Iy80ngsYh4R9VrJ+AfwBXAgVW/AykPtkqSJEl91vYPmEbEicAWwHlVr6MiYtvMnJ+3tXwWOC8iFgMeBg6iXPhcHBGfBB6l/PiSJEmS1Gdtn6wDHwBGZOYbABFxNnAH8/FqxcycCIzsZNBOfS1TkiRJqtcvmsEAy9d8Xq5ZQUiSJEm90R9q1v8XuCMibgCC8o70Y5sbkiRJktSztk/WM/OCiBhPabcewDHVQ6KSJElSS2v7ZjARsSfwcmZekZmXAzMjYo8mhyVJkiT1qO2TdeCbmflCR0dmTgO+2bxwJEmSpMb0h2S9s+/Y9s1/JEmStOjrD8n6bRHxvYhYJyLWjojvAxOaHZQkSZLUk/6QrH8W+A9wEXAx8ApweFMjkiRJkhrQ9s1BMvMlYGxELJ2ZM5odjyRJktSotq9Zj4h3R8Q/gH9U3ZtExI+bHJYkSZLUo7ZP1oHvA7sCzwJk5p2UH0aSJEmSWlp/SNbJzMfqer3elEAkSZKkXmj7NuvAYxHxbiAjYjHgSODeJsckSZIk9ag/1KwfRnn7y2rAFGAEvg1GkiRJi4C2r1nPzGeA0c2OQ5IkSeqttq9Zj4iTImLZiBgcEddFxDMRsV+z45IkSZJ60vbJOrBLZr4IfJDSDGY94EvNDUmSJEnqWX9I1gdX/z8AXJCZzzUzGEmSJKlRbd9mHbgyIu4DXgE+ExFDgZlNjkmSJEnqUdvXrGfmWGBrYGRmvga8DHy4uVFJkiRJPWvbZD0itu34nJnPZ+br1eeXMvPJ6qHTdzYvQkmSJKl77dwM5qMRcRJwNTABmAoMAd4O7AisCXyheeFJkiRJ3WvbZD0zj46IFYCPAXsBq1Lard8L/DQz/9TM+CRJkqSetG2yDqX5C/Cz6k+SJElapLRtm3VJkiRpUWeyLkmSJLUok3VJkiSpRbV9sh4RS0bE1yPiZ1X3uhHxwWbHJUmSJPWk7ZN14EzgVcoPIwFMAY5vXjiSJElSY/pDsr5OZp4EvAaQma8A0dyQJEmSpJ71h2T9PxGxBJAAEbEOpaZdkiRJamlt/Z71yjcpv2K6RkScB2wDjGlqRJIkSVID2j5Zz8z/i4jbga0ozV+OysxnmhyWJEmS1KP+0AwGYDVgILAYsH1EfKTJ8UiSJEk9avua9Yj4JTAcmAS8UfVO4LKmBSVJkiQ1oO2TdWCrzNyw2UFIkiRJvdUfmsHcEhEm65IkSVrk9Iea9bMpCfuTlFc2BpCZOby5YUmSJEnd6w/J+i+B/YG7mdNmXZIkSWp5/SFZfzQzr2h2EJIkSVJv9Ydk/b6IOB+4kppfLs1M3wYjSZKkltYfkvUlKEn6LjX9fHWjJEmSWl7bJ+uZeVCzY5AkSZL6om2T9Yj4cmaeFBE/pNSkzyUzj2xCWJIkSVLD2jZZB+6t/t/W1CgkSZKkPmrbZD0zr6w+vpyZv64dFhF7NSEkSZIkqVf6wy+YHttgP0mSJKmltG3NekS8H/gAsFpEnFozaFlgVnOikiRJkhrXtsk68DilvfruwISa/tOBo5sSkSRJktQLbZusZ+adwJ0RcX5mvtbseCRJkqTeavs26ybqkiRJWlS1fbIuSZIkLapM1iVJkqQW1bZt1jtExHrAl4A1qfm+mfmepgUlSZIkNaDtk3Xg18DpwM+A15sciyRJktSw/pCsz8rMnzQ7CEmSJKm32jZZj4gVq49XRsRngN8Ar3YMz8znmhKYJEmS1KC2TdYpP4SUQFTdX6oZlsDafS04IgZSfnDp35n5werC4CJgGDAZ+HhmPt/X8iVJkiRo47fBZOZambl29b/+r8+JeuUo4N6a7rHAdZm5LnBd1S1JkiTNl7ZN1jtExOERsXxN9wpVs5i+lrc6sBvw85reHwbOrj6fDezR1/IlSZKkDm2frAOHZOa0jo6qecoh81HeD4AvA2/U9FslM5+oyn8CeMt8lC9JkiQB/SNZHxARHe3WO9qbL9aXgiLig8DTmTmhr8FExKERcVtE3DZ16tS+FiNJkqR+oD8k638ELo6InSLiPcAFwNV9LGsbYPeImAxcCLwnIs4FnoqIVQGq/093VUBmnpGZIzNz5NChQ/sYhiRJkvqD/pCsHwNcD/w/4HDKA6Bf7ktBmXlsZq6emcOAfYDrM3M/4ArgwGq0A4HL5zdoSZIkqZ1f3QhAZr4REb8A/kR5ZeP9mbmgf8n0RErt/SeBR4G9FnD5kiRJ6ofaPlmPiFGUN7RMprxzfY2IODAzb5qfcjNzPDC++vwssNP8lCdJkiTVa/tkHfgusEtm3g8QEetR2q1v3tSoJEmSpB70hzbrgzsSdYDM/CcwuInxSJIkSQ3pDzXrt1Vt1n9VdY8G+vzqRUmSJOnN0h+S9Y63wBxJabN+E/DjpkYkSZIkNaDtk/XMfDUifkR5ZeMblLfB/KfJYUmSJEk9avtkPSJ2A04HHqLUrK8VEZ/OzD80NzJJkiSpe22frFPeBrNjZj4IEBHrAFcBJuuSJElqaf3hbTBPdyTqlYeBp5sVjCRJktSo/lCzPikifg9cTPkF072Av0fERwAy87JmBidJkiR1pT8k60OAp4Adqu6pwIrAhyjJu8m6JEmSWlLbJ+uZeVCzY5AkSZL6ou3brEfEehFxXUTcU3UPj4ivNTsuSZIkqSdtn6wDPwOOBV4DyMy7gH2aGpEkSZLUgP6QrC+ZmbfW9ZvVlEgkSZKkXugPyfoz1bvVEyAiPgY80dyQJEmSpJ61/QOmwOHAGcD6EfFv4BFgdHNDkiRJknrW9sl6Zj4M7BwRSwEDMnN6s2OSJEmSGtH2yXqHzHyp2TFIkiRJvdEf2qxLkiRJiySTdUmSJKlF9YtmMBHxbmAYNd83M89pWkCSJElSA9o+WY+IXwHrABOB16veCZisS5IkqaW1fbIOjAQ2zMxsdiCSJElSb/SHNuv3AG9tdhCSJElSb/WHmvWVgX9ExK3Aqx09M3P35oUkSZIk9aw/JOvjmh2AJEmS1Bdtn6xn5o3NjkGSJEnqi7Zvsx4RW0XE3yNiRkT8JyJej4gXmx2XJEmS1JO2T9aBHwH7Ag8ASwCfqvpJkiRJLa3tm8EAZOaDETEwM18HzoyIvzQ7JkmSJKkn/SFZfzkiFgMmRsRJwBPAUk2OSZIkSepRf2gGsz/lex4BvASsAXy0qRFJkiRJDWj7mvXM/FdELAGsmpnHNTseSZIkqVFtX7MeER8CJgJXV90jIuKKpgYlSZIkNaDtk3XKjyJtCUwDyMyJwLCmRSNJkiQ1qD8k67My84VmByFJkiT1Vtu3WQfuiYhPAAMjYl3gSMBXN0qSJKnl9Yea9c8CGwGvAhcALwKfa2ZAkiRJUiPavmY9M18Gvlr9SZIkSYuMtk3We3rjS2bu/mbFIkmSJPVF2ybrwNbAY5SmL38DornhSJIkSb3Tzsn6W4H3AvsCnwCuAi7IzElNjUqSJElqUNs+YJqZr2fm1Zl5ILAV8CAwPiI+2+TQJEmSpIa0c806EbE4sBuldn0YcCpwWTNjkiRJkhrVtsl6RJwNvBP4A3BcZt7T5JAkSZKkXmnbZB3YH3gJWA84MmL286UBZGYu26zAJEmSpEa0bbKemW3bHl+SJEn9gwmtJEmS1KJM1iVJkqQWZbIuSZIktSiTdUmSJKlFmaxLkiRJLcpkXZIkSWpRJuuSJElSizJZlyRJklqUybokSZLUokzWJUmSpBZlsi5JkiS1KJP1XoqINSLihoi4NyImRcRRVf8VI+L/IuKB6v8KzY5VkiRJizaT9d6bBXwhMzcAtgIOj4gNgbHAdZm5LnBd1S1JkiT1mcl6L2XmE5l5e/V5OnAvsBrwYeDsarSzgT2aEqAkSZLahsn6fIiIYcCmwN+AVTLzCSgJPfCWLqY5NCJui4jbpk6d+qbFKkmSpEWPyXofRcTSwKXA5zLzxUany8wzMnNkZo4cOnTowgtQkiRJizyT9T6IiMGURP28zLys6v1URKxaDV8VeLpZ8UmSJKk9mKz3UkQE8Avg3sz8Xs2gK4ADq88HApe/2bFJkiSpvQxqdgCLoG2A/YG7I2Ji1e8rwInAxRHxSeBRYK/mhCdJkqR2YbLeS5n5JyC6GLzTmxmLJEmS2pvNYCRJkqQWZbIuSZIktSiTdUmSJKlFmaxLkiRJLcpkXZIkSWpRJuuSJElSizJZlyRJklqUybokSZLUokzWJUmSpBZlsi5JkiS1KJN1SZIkqUWZrEuSJEktymRdkiRJalEm65IkSVKLMlmXJEmSWpTJuiRJktSiTNYlSZKkFmWyLkmSJLUok3VJkiSpRZmsS5IkSS3KZF2SJElqUSbrkiRJUosyWZckSZJalMm6JEmS1KJM1iVJkqQWZbIuSZIktSiTdUmSJKlFmaxLkiRJLcpkXZIkSWpRg5odgCRJC8qwsVc1O4R+a/KJuzU7BKktWbMuSZIktSiTdUmSJKlFmaxLkiRJLco265Ikaf6NW67ZEfRf415odgRaiKxZlyRJklqUybokSZLUokzWJUmSpBZlsi5JkiS1KJN1SZIkqUWZrEuSJEktymRdkiRJalEm65IkSVKLMlmXJEmSWpTJuiRJktSiTNYlSZKkFmWyLkmSJLUok3VJkiSpRZmsS5IkSS3KZF2SJElqUSbrkiRJUosyWZckSZJalMm6JEmS1KJM1iVJkqQWZbIuSZIktSiTdUmSJKlFmaxLkiRJLcpkXZIkSWpRJusLUES8LyLuj4gHI2Jss+ORJEnSos1kfQGJiIHAacD7gQ2BfSNiw+ZGJUmSpEWZyfqCsyXwYGY+nJn/AS4EPtzkmCRJkrQIG9TsANrIasBjNd1TgHfVjxQRhwKHVp0zIuL+NyE2NUHAysAzzY6jXzoumh2B1O94zGuiN++Yt+abNSPNYbK+4HS2p+Q8PTLPAM5Y+OGo2SLitswc2ew4JOnN4DFPWjhsBrPgTAHWqOleHXi8SbFIkiSpDZisLzh/B9aNiLUiYjFgH+CKJsckSZKkRZjNYBaQzJwVEUcAfwQGAr/MzElNDkvNZXMnSf2JxzxpIYjMeZpVS5IkSWoBNoORJEmSWpTJuiRJktSibLOufiEiVgKuqzrfCrwOTK26t6x+yKqraUcCB2Tmkb2Y32RgejUfgJt6M30D5c/IzKUXVHmS2tf8HP+q6UcB/8nMv3QybAzwHeDfNb0/kZn/mL+oZ5c/DpiRmScviPKkRZHJuvqFzHwWGAGdH/wjYlBmzupi2tuA2/ow2x0z0x8IkdRUPR3/GjAKmAHMk6xXLsrMI+YjREndsBmM+q2IOCsivhcRNwDfjogtI+IvEXFH9f8d1XijIuJ31edxEfHLiBgfEQ9HRK9qy6vpflCVf09EbFn1XzEifhsRd0XEXyNieNV/6Yg4MyLuroZ9tKasEyLizmr8VRbYgpHU9iJi84i4MSImRMQfI2LVqv+REfGP6nhzYUQMAw4Djo6IiRGxXYPlj4qImyLiN1V5p0fEgGrYvtUx7Z6I+HbNNO+LiNur49p1NcVt2NdjrtQOrFlXf7cesHNmvh4RywLbV6/h3Bn4FvDRTqZZH9gRWAa4PyJ+kpmvdTLeDRHR0Qzm7Mz8fvV5qcx8d0RsD/wSeCdwHHBHZu4REe8BzqHUhH0deCEzNwaIiBU6ygD+mplfjYiTgEOA4+dnQUjqNwL4IfDhzJwaEXsDJwAHA2OBtTLz1YhYPjOnRcTpdF8bv3dEbFvTvXX1f0tgQ+BfwNXARyLiL8C3gc2B54FrImIP4M/AzyjH4EciYsWa8ho95kptyWRd/d2vM7MjoV4OODsi1gUSGNzFNFdl5qvAqxHxNLAK5Rds63XVDOYCgMy8KSKWjYjlgW2pLgwy8/qIWCkilgN2pvzAFtWw56uP/wF+V32eALy3oW8rSbA4pZLg/yICym+DPFENuws4LyJ+C/y2wfLmaQZTlXtrZj5cdV9AOc69BozPzKlV//OA7Snt6G/KzEcAMvO5muIaPeZKbclkXf3dSzWf/we4ITP3rG79ju9imldrPr9O7/ej+h83SEpNV2fjRSfjA7yWc34koS8xSOq/ApiUmVt3Mmw3SvK8O/D1iNhoPubT6LGuI6aufvhlfo+50iLNNuvSHMsx540GYxbifPYGqG4bv5CZLwA3AaOr/qOAZzLzReAaYHaNVU0zGEnqq1eBoRGxNUBEDI6Ijao25Wtk5g3Al4HlgaUpb7Zapg/z2TIi1qrK3Rv4E/A3YIeIWDkiBgL7AjcCt1T916piWrGrQqX+xmRdmuMk4H8j4s+U28Lz64bqgayJEXFOTf/nq3abpwOfrPqNA0ZGxF3AicCBVf/jgRWqB7HupLTblKT58QbwMcqD9XcCE4F3U45750bE3cAdwPczcxpwJbBnNw+Y7l1zrJsYEe+u+t9COZ7dAzwC/CYznwCOBW4A7gRuz8zLq2YxhwKXVTFdtFC+ubQIijl30iUtbBExHvhi9TpISWpL1R3CL2bmB5scirTIs2ZdkiRJalHWrEuSJEktypp1SZIkqUWZrEuSJEktymRdkiRJalEm65IkSVKLMlmXJEmSWtT/B5a0U8drUHROAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"pytorch_2_results/figures\", exist_ok=True)\n",
    "save_path_multi_run = f\"pytorch_2_results/figures/multi_run_{gpu_name}_{model_name}_{dataset_name}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "plot_mean_epoch_times(non_compile_results_multiple_runs_df, compile_results_multiple_runs_df, multi_runs=True, num_runs=NUM_RUNS, save_path=save_path_multi_run, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_run_non_compiled_results_3_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n",
      "multi_run_compiled_results_3_runs_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_4080.csv\n"
     ]
    }
   ],
   "source": [
    "save_name_for_multi_run_non_compiled_results = f\"multi_run_non_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "save_name_for_multi_run_compiled_results = f\"multi_run_compiled_results_{NUM_RUNS}_runs_{dataset_name}_{model_name}_{gpu_name.replace(' ', '_')}.csv\"\n",
    "print(save_name_for_multi_run_non_compiled_results)\n",
    "print(save_name_for_multi_run_compiled_results)\n",
    "\n",
    "# Make a directory for multi_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_multi_run_results_dir = f\"{pytorch_2_results_dir}/multi_run_results\"\n",
    "os.makedirs(pytorch_2_multi_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_non_compiled_results}\")\n",
    "compile_results_df.to_csv(f\"{pytorch_2_multi_run_results_dir}/{save_name_for_multi_run_compiled_results}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TK - Possible improvements/extensions\n",
    "\n",
    "* TK - use mixed precision training - https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples (more speedups)\n",
    "* Transformer based models may see better speedups than conv models (due to PyTorch 2.0) - https://pytorch.org/blog/pytorch-2.0-release/#stable-accelerated-pytorch-2-transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
